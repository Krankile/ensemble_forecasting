{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_feature_extractor.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQ4eora4F1rcE+o7vNM8/N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krankile/ensemble-forcasting/blob/main/LSTM_feature_extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NOjedVwhAX9"
      },
      "source": [
        "# New change\n",
        "from torch import nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHTU63O-mphv"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "  def __init__(self, seq_len, n_features, embedding_dim=64):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.seq_len, self.n_features = seq_len, n_features\n",
        "    self.embedding_dim, self.hidden_dim = embedding_dim, 2 * embedding_dim\n",
        "\n",
        "    self.rnn1 = nn.LSTM(\n",
        "      input_size=n_features,\n",
        "      hidden_size=self.hidden_dim,\n",
        "      num_layers=1,\n",
        "      batch_first=True\n",
        "    )\n",
        "    \n",
        "    self.rnn2 = nn.LSTM(\n",
        "      input_size=self.hidden_dim,\n",
        "      hidden_size=embedding_dim,\n",
        "      num_layers=1,\n",
        "      batch_first=True\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.reshape((1, self.seq_len, self.n_features))\n",
        "\n",
        "    x, (_, _) = self.rnn1(x)\n",
        "    x, (hidden_n, _) = self.rnn2(x)\n",
        "\n",
        "    return hidden_n.reshape((self.n_features, self.embedding_dim))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOb6k8p4x7Ck"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "  def __init__(self, seq_len, input_dim=64, n_features=1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.seq_len, self.input_dim = seq_len, input_dim\n",
        "    self.hidden_dim, self.n_features = 2 * input_dim, n_features\n",
        "\n",
        "    self.rnn1 = nn.LSTM(\n",
        "      input_size=input_dim,\n",
        "      hidden_size=input_dim,\n",
        "      num_layers=1,\n",
        "      batch_first=True\n",
        "    )\n",
        "\n",
        "    self.rnn2 = nn.LSTM(\n",
        "      input_size=input_dim,\n",
        "      hidden_size=self.hidden_dim,\n",
        "      num_layers=1,\n",
        "      batch_first=True\n",
        "    )\n",
        "\n",
        "    self.output_layer = nn.Linear(self.hidden_dim, n_features)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.repeat(self.seq_len, self.n_features)\n",
        "    x = x.reshape((self.n_features, self.seq_len, self.input_dim))\n",
        "\n",
        "    x, (hidden_n, cell_n) = self.rnn1(x)\n",
        "    x, (hidden_n, cell_n) = self.rnn2(x)\n",
        "    x = x.reshape((self.seq_len, self.hidden_dim))\n",
        "\n",
        "    return self.output_layer(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0cLmAB0yEXE"
      },
      "source": [
        "class RecurrentAutoencoder(nn.Module):\n",
        "\n",
        "  def __init__(self, seq_len, n_features, embedding_dim=64):\n",
        "    super(RecurrentAutoencoder, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(seq_len, n_features, embedding_dim).to(device)\n",
        "    self.decoder = Decoder(seq_len, embedding_dim, n_features).to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = self.decoder(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fytZWUOhyMe0"
      },
      "source": [
        "def train_model(model, train_dataset, val_dataset, n_epochs):\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "  criterion = nn.L1Loss(reduction='sum').to(device)\n",
        "  history = dict(train=[], val=[])\n",
        "\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_loss = 10000.0\n",
        "  \n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    model = model.train()\n",
        "\n",
        "    train_losses = []\n",
        "    for seq_true in train_dataset:\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      seq_true = seq_true.to(device)\n",
        "      seq_pred = model(seq_true)\n",
        "\n",
        "      loss = criterion(seq_pred, seq_true)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      train_losses.append(loss.item())\n",
        "\n",
        "    val_losses = []\n",
        "    model = model.eval()\n",
        "    with torch.no_grad():\n",
        "      for seq_true in val_dataset:\n",
        "\n",
        "        seq_true = seq_true.to(device)\n",
        "        seq_pred = model(seq_true)\n",
        "\n",
        "        loss = criterion(seq_pred, seq_true)\n",
        "        val_losses.append(loss.item())\n",
        "\n",
        "    train_loss = np.mean(train_losses)\n",
        "    val_loss = np.mean(val_losses)\n",
        "\n",
        "    history['train'].append(train_loss)\n",
        "    history['val'].append(val_loss)\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "      best_loss = val_loss\n",
        "      best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    print(f'Epoch {epoch}: train loss {train_loss} val loss {val_loss}')\n",
        "\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  return model.eval(), history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYKa_AzAyWxE"
      },
      "source": [
        "model = RecurrentAutoencoder(seq_len, n_features, 128)\n",
        "model = model.to(device)\n",
        "\n",
        "train_dataset = nn.Tensor([\n",
        "    [1, 2, 3,],\n",
        "    [4, 5, 6,],\n",
        "    [7, 8, 9,],\n",
        "])\n",
        "\n",
        "val_dataset = nn.Tensor([\n",
        "    [1, 2, 3,],\n",
        "    [4, 5, 6,],\n",
        "    [7, 8, 9,],\n",
        "])\n",
        "\n",
        "model, history = train_model(\n",
        "  model, \n",
        "  train_dataset, \n",
        "  val_dataset, \n",
        "  n_epochs=150\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}