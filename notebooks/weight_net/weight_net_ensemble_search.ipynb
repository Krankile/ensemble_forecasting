{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "weight_net_ensemble_search.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "z9qWiol8h6A1"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6176e86148c249c4b30d1009c841774c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_67f73c6d539d40d79b0103c92734a89c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f2bc3c7f1a6445f1a2697fddf5b9d879",
              "IPY_MODEL_71e6d478f5054144b47d26d41f9dd1ea"
            ]
          }
        },
        "67f73c6d539d40d79b0103c92734a89c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2bc3c7f1a6445f1a2697fddf5b9d879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_3a41c8382e714cdabe3a2693c82ba3d7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8.38MB of 8.38MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_807de5dc865746dc8ab6e1d3e9b0f5c6"
          }
        },
        "71e6d478f5054144b47d26d41f9dd1ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_35ff6974be4c4db3865b89c6778fa916",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7839b2f2d334bed8b25e1ab03393ee7"
          }
        },
        "3a41c8382e714cdabe3a2693c82ba3d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "807de5dc865746dc8ab6e1d3e9b0f5c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35ff6974be4c4db3865b89c6778fa916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7839b2f2d334bed8b25e1ab03393ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96d8b23780484bb9b977aa03ded1d56f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c93b56728b0948ddbba176f246f9bb91",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_531c027576b44b1fbb7cba04f500b189",
              "IPY_MODEL_68567a68f4b243818e99806cd7fe86e7"
            ]
          }
        },
        "c93b56728b0948ddbba176f246f9bb91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "531c027576b44b1fbb7cba04f500b189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_f977e3d930ac4f659236eb2f530863bb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8.38MB of 8.38MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c189e07c1f054421aedefd210fe2a38c"
          }
        },
        "68567a68f4b243818e99806cd7fe86e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2cf52c96b3354405b2ababe00f925740",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ac01ee2afad444ebf84b4d2c15583ac"
          }
        },
        "f977e3d930ac4f659236eb2f530863bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c189e07c1f054421aedefd210fe2a38c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2cf52c96b3354405b2ababe00f925740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ac01ee2afad444ebf84b4d2c15583ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krankile/ensemble_forecasting/blob/main/notebooks/weight_net/weight_net_ensemble_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad2rmI-1IBOy"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbUYg-ygNho7"
      },
      "source": [
        "%%capture\n",
        "!pip install pytorch-forecasting kora wandb"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs7aB3tB1uMl"
      },
      "source": [
        "Go here to find wandb API key:\n",
        "\n",
        "[https://wandb.ai/settings](https://wandb.ai/settings)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbiRr31H-t9b",
        "outputId": "1dd8d89a-7c9a-4949-b28c-2d1c85129a13"
      },
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "\n",
        "from kora import drive\n",
        "drive.link_nbs()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkrankile\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Oo7lgF2HeDZ"
      },
      "source": [
        "import os\n",
        "import copy\n",
        "import math\n",
        "import random\n",
        "from multiprocessing import cpu_count\n",
        "from pathlib import Path\n",
        "from collections import namedtuple\n",
        "import itertools\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler , minmax_scale, StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from pytorch_forecasting.metrics import SMAPE"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eisYRCr-rqs8",
        "outputId": "f356f3bc-899e-49b9-9b6d-304d77ac3ead"
      },
      "source": [
        "ROOT = Path(\"/content/drive/MyDrive/Master, Ankile og Krange\")\n",
        "ROOT"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/MyDrive/Master, Ankile og Krange')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbGDaQzgSr7y",
        "outputId": "f3d078e7-4d02-4f02-fc44-e407cf66610f"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObdD3c7cVo0e"
      },
      "source": [
        "## Define loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VNeSqUjnh1J"
      },
      "source": [
        "def mase(pred, actual, *args):\n",
        "    divs, *_ = args\n",
        "    return torch.div(nn.functional.l1_loss(pred, actual, reduction=\"none\").sum(1), divs).mean()\n",
        "\n",
        "def smape(pred, actual, *args):\n",
        "    *_, h = args\n",
        "    return 200 * torch.div(((pred - actual).abs() / (pred.abs() + actual.abs() + 1e-40)).sum(1), h).mean()\n",
        "\n",
        "def owa(pred, actual, *args):\n",
        "    _, n_smape, n_mase, __ = args\n",
        "    return 0.5*(torch.div(smape(pred, actual, *args), n_smape.mean()) + torch.div(mase(pred, actual, *args), n_mase.mean()))\n",
        "\n",
        "class NoneScheduler:\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        pass\n",
        "    \n",
        "    def step(self):\n",
        "        pass\n",
        "\n",
        "activations = {\n",
        "    \"relu\": nn.ReLU, \n",
        "    \"elu\": nn.ELU, \n",
        "    \"leaky\": nn.LeakyReLU, \n",
        "}\n",
        "\n",
        "optimizers = {\n",
        "    \"adam\": torch.optim.Adam,\n",
        "    \"sgd\": torch.optim.SGD,\n",
        "    \"adamw\": torch.optim.AdamW,\n",
        "}\n",
        "\n",
        "loss_functions = {\n",
        "    \"smape\": smape,\n",
        "    \"mse\": nn.MSELoss().to(device),\n",
        "    \"mase\": mase,\n",
        "    \"owa\": owa,\n",
        "}\n",
        "\n",
        "schedulers = {\n",
        "    \"onecyclelr\": optim.lr_scheduler.OneCycleLR,\n",
        "    None: NoneScheduler\n",
        "}\n",
        "\n",
        "scalers = {\n",
        "    \"minmax\": MinMaxScaler(feature_range=(-1,1)),\n",
        "    \"standard\": StandardScaler(),\n",
        "}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FllsF0c6IEIq"
      },
      "source": [
        "#Build net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZr84jKdIsVk"
      },
      "source": [
        "class WeightNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_cont, out_size, n_hidden, hidden_dim, dropout, bn, activation, emb_dims):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(x, y) for x, y in emb_dims])\n",
        "        self.num_embs = sum([y for x, y in emb_dims])\n",
        "        self.num_cont = num_cont\n",
        "\n",
        "        layers = [nn.Linear(self.num_embs + self.num_cont, hidden_dim)]\n",
        "\n",
        "        self.first_bn = nn.BatchNorm1d(self.num_cont)\n",
        "\n",
        "        for i in range(n_hidden):\n",
        "            layers.extend(\n",
        "                [nn.Dropout(p=dropout)]\n",
        "                +[nn.BatchNorm1d(hidden_dim)] if bn else []\n",
        "                +[activations[activation]()]\n",
        "            )\n",
        "            if i == (n_hidden - 1):\n",
        "                layers.append(nn.Linear(hidden_dim, out_size))\n",
        "            else:\n",
        "                layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "\n",
        "        self.fc = nn.Sequential(*layers)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, cat, cont):\n",
        "        x = [emb(cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
        "        x = torch.cat(x, 1)\n",
        "\n",
        "        cont = self.first_bn(cont)\n",
        "        \n",
        "        x = torch.cat([x, cont], 1) \n",
        "        x = self.fc(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhZaI8E_IGcJ"
      },
      "source": [
        "#Create training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yboW4zVraNz7"
      },
      "source": [
        "## Feature extractor\n",
        "Load the training dataframe of size 90,000 x 527"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FNQINPvmWXl"
      },
      "source": [
        " def feature_extractor(df, manual_auto_tp_toggle, normalization, model_list):\n",
        "     \n",
        "    batch_size = df.shape[0]\n",
        "    idxs = df.index.to_numpy()\n",
        "\n",
        "    #Get forecasts\n",
        "    n_models = len(model_list)\n",
        "    columns = []\n",
        "    for model in model_list:\n",
        "        columns += [f\"{model}_{i}\" for i in range(48)]\n",
        "    forecasts = df.loc[:,columns]\n",
        "\n",
        "    #Get feature inputs \n",
        "    if manual_auto_tp_toggle == \"\":\n",
        "        raise Exception(\"Manual_or_auto_toggle needs to cointain either m or a for input to be non-empty\")\n",
        "\n",
        "\n",
        "    inputs_start = \"x_acf1\" if \"m\" in manual_auto_tp_toggle.lower() else \"lstm_0\"\n",
        "    inputs_end = \"lstm_31\" if \"a\" in manual_auto_tp_toggle.lower() else \"series_length\"\n",
        "    \n",
        "    inputs = df.loc[:, inputs_start:inputs_end]\n",
        "    \n",
        "    inputs_cat = df.loc[:, ['type', 'period']].astype(\"category\")\n",
        "    emb_dims = [(x, min(x // 2, 50)) for x in map(lambda y: len(inputs_cat[y].cat.categories), inputs_cat)]\n",
        "    \n",
        "    for col in inputs_cat:\n",
        "        inputs_cat[col] = inputs_cat[col].cat.codes\n",
        "\n",
        "    inputs_cat = torch.as_tensor(inputs_cat.to_numpy(), dtype=torch.long)\n",
        "\n",
        "    scaler = scalers[normalization]\n",
        "    inputs_normalized = scaler.fit_transform(inputs.to_numpy())\n",
        "\n",
        "    #Get actuals \n",
        "    actuals = df.loc[:, \"actual_0\":\"actual_47\"].to_numpy()\n",
        "    forecasts = forecasts.to_numpy().reshape((batch_size, n_models, 48)).swapaxes(1, 2)\n",
        "\n",
        "    return (inputs_cat, emb_dims), inputs_normalized, forecasts, actuals"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gr3144xh25N"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nUjLCeqpPOQ"
      },
      "source": [
        "class M4Data(Dataset):\n",
        "    \n",
        "    def __init__(self, meta_path, loss_path, manual_or_auto_toggle, models, type_of_normalization=\"standard\"):\n",
        "        meta_df = pd.read_feather(meta_path).set_index(\"index\").replace(np.nan, 0)\n",
        "        loss_df = pd.read_feather(loss_path).set_index(\"st\").loc[meta_df.index]\n",
        "\n",
        "        self.h = meta_df[\"h\"].astype(np.int16)\n",
        "        self.divs = loss_df[\"mase_divisor\"]\n",
        "        self.n_smape = loss_df[\"naive2_smape\"]\n",
        "        self.n_mase = loss_df[\"naive2_mase\"]\n",
        "\n",
        "        self.index = meta_df.index.values\n",
        "        self.length = meta_df.shape[0]\n",
        "  \n",
        "        (self.cats, emb_dims), self.input, self.forecast, self.actuals = feature_extractor(meta_df, manual_or_auto_toggle, type_of_normalization, models)\n",
        "\n",
        "        self.num_cont = self.input.shape[1]\n",
        "        self.emb_dims = emb_dims\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.cats[idx], self.input[idx], self.forecast[idx], self.actuals[idx], self.divs[idx], self.n_smape[idx], self.n_mase[idx], self.h[idx]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z3BeYoaqwLL"
      },
      "source": [
        "def get_dataloaders(train_path, val_path, loss_train_path, loss_val_path, batch_size, manual_or_auto_toggle, models, normalize=\"standard\"):\n",
        "    \n",
        "    cpus = cpu_count()\n",
        "    print(f\"CPU count: {cpus}\")\n",
        "    train_data = M4Data(train_path, loss_train_path, manual_or_auto_toggle, models, normalize)\n",
        "    val_data = M4Data(val_path, loss_val_path, manual_or_auto_toggle, models, normalize)\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=cpus, drop_last=True)\n",
        "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=cpus)\n",
        "\n",
        "    return train_loader, val_loader, train_data.emb_dims, train_data.num_cont, train_data.length"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJJhNFTgq2YF"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HafRiXtVZ80M"
      },
      "source": [
        "def train_model(model, train_loader, val_loader, num_examples, conf):    \n",
        "    batch_size = conf.batch_size\n",
        "\n",
        "    optimizer = optimizers[conf.optimizer](model.parameters(), lr=conf.learning_rate, weight_decay=conf.weight_decay)\n",
        "    scheduler = schedulers[conf.schedule](\n",
        "        optimizer, conf.learning_rate,\n",
        "        epochs=conf.epochs,\n",
        "        steps_per_epoch=math.ceil(num_examples / batch_size),\n",
        "    )\n",
        "\n",
        "    loss_func = loss_functions[conf.loss_func]\n",
        "    train_loss_plot = []\n",
        "    val_loss_plot = []\n",
        "    it = tqdm(range(1, conf.epochs+1))\n",
        "    \n",
        "    best_loss = float(\"inf\")\n",
        "    step = 0\n",
        "\n",
        "    for epoch in it:\n",
        "\n",
        "        #Each epoch has a training and validation phase\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        for phase in ['train','val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "                batches = train_loader\n",
        "            else:\n",
        "                model.eval()  # Set model to evaluate mode\n",
        "                batches = val_loader\n",
        "            for i, tensors in enumerate(batches):\n",
        "                cats, inputs, forecasts, actuals, *loss_args = map(lambda x: x.to(device), tensors)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                y_pred = model(cats, inputs).unsqueeze(2)\n",
        "                prediction = torch.matmul(forecasts, y_pred).squeeze(2)\n",
        "                loss = loss_func(prediction, actuals, *loss_args)\n",
        "                if phase == 'train':\n",
        "                    train_losses.append(loss.item())\n",
        "                    loss.backward()\n",
        "\n",
        "                    optimizer.step()\n",
        "                    scheduler.step()\n",
        "                    \n",
        "                    step += 1\n",
        "                else:\n",
        "                    val_losses.append(loss.item())\n",
        "\n",
        "        train_loss = np.mean(train_losses)\n",
        "        val_loss = np.mean(val_losses)\n",
        "\n",
        "        if val_loss < best_loss: \n",
        "            best_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            filepath = \"model.torch\"\n",
        "            torch.save(best_model_wts, filepath)\n",
        "            wandb.save(filepath)\n",
        "\n",
        "        train_mean = np.mean(train_loss)\n",
        "        val_mean = np.mean(val_loss)\n",
        "        wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss, \"epoch\": epoch, \"best_loss\": best_loss, \"n_examples\":batch_size*step, \"lr\": optimizer.param_groups[0][\"lr\"]}, step=step)\n",
        "        it.set_postfix({\"train_loss\": train_mean, \"val_loss\": val_mean, \"best_loss\": best_loss, \"lr\": f'{optimizer.param_groups[0][\"lr\"]:.2e}'})\n",
        "        \n",
        "        train_loss_plot.append(train_mean)\n",
        "        val_loss_plot.append(val_mean)\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model.eval()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txgaemzlh9DO"
      },
      "source": [
        "## Run config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyJs3OK-iAxs"
      },
      "source": [
        "all_models = [\"auto_arima_forec\" , \"ets_forec\", \"nnetar_forec\", \"tbats_forec\", \"stlm_ar_forec\", \"rw_drift_forec\", \"theta_forec\", \"naive_forec\", \"snaive_forec\", \"ols\", \"uhlenbeck\", \"lgt\", \"quant_99_reg\", \"quant_01_reg\"]\n",
        "\n",
        "defaultconfig = dict(\n",
        "    epochs=50,\n",
        "    hidden_dim=1024,\n",
        "    learning_rate=2e-3,\n",
        "    architecture=\"weight_net_v06\",\n",
        "    batch_size=2048,\n",
        "    optimizer=\"adamw\",\n",
        "    loss_func=\"owa\",\n",
        "    dropout=0.3,\n",
        "    manual_or_auto_toggle=\"ma\",\n",
        "    normalize_data=\"standard\",\n",
        "    weight_decay=0.05,\n",
        "    act=\"leaky\",\n",
        "    bn=False,\n",
        "    n_hidden=3,\n",
        "    schedule=None,\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7-FhB-RV27-"
      },
      "source": [
        "##Begin training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXNHySSwjXyY"
      },
      "source": [
        "def train(config=defaultconfig, project=None, entity=None, enablewb=True):\n",
        "    mode = \"online\" if enablewb else \"disabled\"\n",
        "\n",
        "    torch.manual_seed(69)\n",
        "\n",
        "    with wandb.init(config=config, project=project, entity=entity, job_type=\"training\", mode=mode) as run:\n",
        "        \n",
        "        models = list(itertools.combinations(all_models, 9))[run.config.ensemble_index]\n",
        "        run.config.setdefaults({**run.config, \"models\": models})\n",
        "        \n",
        "        conf = run.config\n",
        "        print(conf)\n",
        "\n",
        "        train_path = ROOT / 'Data/Meta/m4_meta_am_train_14m.feather'\n",
        "        val_path = ROOT / 'Data/Meta/m4_meta_am_val_14m.feather'\n",
        "        loss_train_path = ROOT / 'Data/loss_functions/loss_func_train.feather'\n",
        "        loss_val_path = ROOT / 'Data/loss_functions/loss_func_val.feather'\n",
        "\n",
        "        \n",
        "        (train_loader,\n",
        "         val_loader,\n",
        "         emb_dims,\n",
        "         num_cont,\n",
        "         num_examples) = get_dataloaders(train_path,val_path,\n",
        "                                         loss_train_path, loss_val_path,\n",
        "                                         conf.batch_size, conf.manual_or_auto_toggle,\n",
        "                                         conf.models, conf.normalize_data)\n",
        "\n",
        "        model = WeightNet(\n",
        "            num_cont=num_cont,\n",
        "            out_size=len(models),\n",
        "            n_hidden=conf.n_hidden,\n",
        "            hidden_dim=conf.hidden_dim,\n",
        "            dropout=conf.dropout,\n",
        "            bn=conf.bn,\n",
        "            activation=conf.act,\n",
        "            emb_dims=emb_dims,\n",
        "        )\n",
        "\n",
        "        print(f\"Moving model to device: {device}\")\n",
        "        model = model.to(device)\n",
        "\n",
        "        model = train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            num_examples,\n",
        "            conf=conf,\n",
        "        )\n",
        "    return model\n",
        "    "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnxXZCSOiCnW"
      },
      "source": [
        "## Start run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6176e86148c249c4b30d1009c841774c",
            "67f73c6d539d40d79b0103c92734a89c",
            "f2bc3c7f1a6445f1a2697fddf5b9d879",
            "71e6d478f5054144b47d26d41f9dd1ea",
            "3a41c8382e714cdabe3a2693c82ba3d7",
            "807de5dc865746dc8ab6e1d3e9b0f5c6",
            "35ff6974be4c4db3865b89c6778fa916",
            "f7839b2f2d334bed8b25e1ab03393ee7",
            "96d8b23780484bb9b977aa03ded1d56f",
            "c93b56728b0948ddbba176f246f9bb91",
            "531c027576b44b1fbb7cba04f500b189",
            "68567a68f4b243818e99806cd7fe86e7",
            "f977e3d930ac4f659236eb2f530863bb",
            "c189e07c1f054421aedefd210fe2a38c",
            "2cf52c96b3354405b2ababe00f925740",
            "2ac01ee2afad444ebf84b4d2c15583ac"
          ]
        },
        "id": "wE0qbeQFwyk0",
        "outputId": "2166b4d2-d29c-4b1a-e430-72854011d847"
      },
      "source": [
        "sweep = True\n",
        "\n",
        "if sweep:\n",
        "    count = 500 # number of runs to execute\n",
        "    wandb.agent(\"krankile/weight-net/by9p52t2\", function=train, count=count)\n",
        "else:\n",
        "    train(config=defaultconfig, project=\"weight-net\", entity=\"Krankile\", enablewb=False)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yh5wnknh with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tensemble_index: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/krankile/weight-net/runs/yh5wnknh\" target=\"_blank\">wandering-sweep-1</a></strong> to <a href=\"https://wandb.ai/krankile/weight-net\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "Sweep page: <a href=\"https://wandb.ai/krankile/weight-net/sweeps/by9p52t2\" target=\"_blank\">https://wandb.ai/krankile/weight-net/sweeps/by9p52t2</a><br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('auto_arima_forec', 'ets_forec', 'nnetar_forec', 'tbats_forec', 'stlm_ar_forec', 'rw_drift_forec', 'theta_forec', 'naive_forec', 'snaive_forec')\n",
            "{'ensemble_index': 0, 'epochs': 50, 'hidden_dim': 1024, 'learning_rate': 0.002, 'architecture': 'weight_net_v06', 'batch_size': 2048, 'optimizer': 'adamw', 'loss_func': 'owa', 'dropout': 0.3, 'manual_or_auto_toggle': 'ma', 'normalize_data': 'standard', 'weight_decay': 0.05, 'act': 'leaky', 'bn': False, 'n_hidden': 3, 'schedule': None, 'models': ['auto_arima_forec', 'ets_forec', 'nnetar_forec', 'tbats_forec', 'stlm_ar_forec', 'rw_drift_forec', 'theta_forec', 'naive_forec', 'snaive_forec']}\n",
            "CPU count: 2\n",
            "Moving model to device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [03:04<00:00,  3.70s/it, train_loss=0.797, val_loss=0.813, best_loss=0.811, lr=2.00e-03]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 6354... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6176e86148c249c4b30d1009c841774c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 8.37MB of 8.37MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_loss</td><td>████████████████████████████████████▂▂▂▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>n_examples</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>████████████████████████████████████▃▃▂▁</td></tr><tr><td>val_loss</td><td>████████████████████████████████████▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
              "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_loss</td><td>0.81121</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>lr</td><td>0.002</td></tr><tr><td>n_examples</td><td>4403200</td></tr><tr><td>train_loss</td><td>0.79743</td></tr><tr><td>val_loss</td><td>0.81273</td></tr></table>\n",
              "</div></div>\n",
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">wandering-sweep-1</strong>: <a href=\"https://wandb.ai/krankile/weight-net/runs/yh5wnknh\" target=\"_blank\">https://wandb.ai/krankile/weight-net/runs/yh5wnknh</a><br/>\n",
              "Find logs at: <code>./wandb/run-20211127_192807-yh5wnknh/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xq7cx7ae with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tensemble_index: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/krankile/weight-net/runs/xq7cx7ae\" target=\"_blank\">azure-sweep-2</a></strong> to <a href=\"https://wandb.ai/krankile/weight-net\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "Sweep page: <a href=\"https://wandb.ai/krankile/weight-net/sweeps/by9p52t2\" target=\"_blank\">https://wandb.ai/krankile/weight-net/sweeps/by9p52t2</a><br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('auto_arima_forec', 'ets_forec', 'nnetar_forec', 'tbats_forec', 'stlm_ar_forec', 'rw_drift_forec', 'theta_forec', 'naive_forec', 'ols')\n",
            "{'ensemble_index': 1, 'epochs': 50, 'hidden_dim': 1024, 'learning_rate': 0.002, 'architecture': 'weight_net_v06', 'batch_size': 2048, 'optimizer': 'adamw', 'loss_func': 'owa', 'dropout': 0.3, 'manual_or_auto_toggle': 'ma', 'normalize_data': 'standard', 'weight_decay': 0.05, 'act': 'leaky', 'bn': False, 'n_hidden': 3, 'schedule': None, 'models': ['auto_arima_forec', 'ets_forec', 'nnetar_forec', 'tbats_forec', 'stlm_ar_forec', 'rw_drift_forec', 'theta_forec', 'naive_forec', 'ols']}\n",
            "CPU count: 2\n",
            "Moving model to device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [02:58<00:00,  3.56s/it, train_loss=0.637, val_loss=0.782, best_loss=0.778, lr=2.00e-03]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 7438... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96d8b23780484bb9b977aa03ded1d56f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 8.37MB of 8.37MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_loss</td><td>█▆▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>n_examples</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▂▁▁▂▂▂▁▂▁▂▁▂▂▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
              "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_loss</td><td>0.77834</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>lr</td><td>0.002</td></tr><tr><td>n_examples</td><td>4403200</td></tr><tr><td>train_loss</td><td>0.6372</td></tr><tr><td>val_loss</td><td>0.7819</td></tr></table>\n",
              "</div></div>\n",
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">azure-sweep-2</strong>: <a href=\"https://wandb.ai/krankile/weight-net/runs/xq7cx7ae\" target=\"_blank\">https://wandb.ai/krankile/weight-net/runs/xq7cx7ae</a><br/>\n",
              "Find logs at: <code>./wandb/run-20211127_193126-xq7cx7ae/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2r0x52fv with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tensemble_index: 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/krankile/weight-net/runs/2r0x52fv\" target=\"_blank\">skilled-sweep-5</a></strong> to <a href=\"https://wandb.ai/krankile/weight-net\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "Sweep page: <a href=\"https://wandb.ai/krankile/weight-net/sweeps/by9p52t2\" target=\"_blank\">https://wandb.ai/krankile/weight-net/sweeps/by9p52t2</a><br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('auto_arima_forec', 'ets_forec', 'nnetar_forec', 'tbats_forec', 'stlm_ar_forec', 'rw_drift_forec', 'theta_forec', 'naive_forec', 'quant_99_reg')\n",
            "{'ensemble_index': 4, 'epochs': 50, 'hidden_dim': 1024, 'learning_rate': 0.002, 'architecture': 'weight_net_v06', 'batch_size': 2048, 'optimizer': 'adamw', 'loss_func': 'owa', 'dropout': 0.3, 'manual_or_auto_toggle': 'ma', 'normalize_data': 'standard', 'weight_decay': 0.05, 'act': 'leaky', 'bn': False, 'n_hidden': 3, 'schedule': None, 'models': ['auto_arima_forec', 'ets_forec', 'nnetar_forec', 'tbats_forec', 'stlm_ar_forec', 'rw_drift_forec', 'theta_forec', 'naive_forec', 'quant_99_reg']}\n",
            "CPU count: 2\n",
            "Moving model to device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 30/50 [01:41<01:04,  3.23s/it, train_loss=0.671, val_loss=0.776, best_loss=0.774, lr=2.00e-03]\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAVoN9LLfyJl"
      },
      "source": [
        "# Start search over nCr ensembles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abEao3pTz7FS"
      },
      "source": [
        "#Run a net over test data and get sMAPE, OWA, and MAE loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn3Voft10Hmr"
      },
      "source": [
        "Load test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpSfNdbvz6VA"
      },
      "source": [
        "test_df = pd.read_feather(\"/content/drive/MyDrive/Master, Ankile og Krange/Data/Meta/m4_meta_am_test.feather\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcKI5fJq0ioE"
      },
      "source": [
        "Load the net from wandb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU4v32i_0nus"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npwDo9MM0ow8"
      },
      "source": [
        "Make the loss loop "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgdLTK7q0lvk"
      },
      "source": [
        "def test_loss(df, runpath, loss_function, use_meta):\n",
        "    root = \"/content/drive/MyDrive/Master, Ankile og Krange/\"\n",
        "\n",
        "    modelpath = root + runpath + \"model.torch\"\n",
        "    configpath = root + runpath + \"config.yaml\"\n",
        "\n",
        "    params = dict(\n",
        "        config=configpath,\n",
        "        project=\"lstm-vae\",\n",
        "        entity=\"krankile\",\n",
        "        job_type=\"smape-testset\",\n",
        "        mode=\"disabled\",\n",
        "    )\n",
        "\n",
        "    inputs, forecasts, actuals, mask = feature_extractor(df, \"am\", \"standard\", use_meta=use_meta)\n",
        "\n",
        "    with wandb.init(**params) as run:\n",
        "        conf = run.config\n",
        "\n",
        "        model = Dense_net(\n",
        "            in_size=inputs.shape[1],\n",
        "            out_size=9, #len(config.models),\n",
        "            dropout_1=conf.dropout_1,\n",
        "            dropout_2=conf.dropout_2,\n",
        "            hidden_dim1=conf.hidden_dim1,\n",
        "            hidden_dim2=conf.hidden_dim2,\n",
        "        )\n",
        "\n",
        "    print(modelpath)\n",
        "    model.load_state_dict(torch.load(modelpath))\n",
        "    model = model.eval()\n",
        "    print(model)\n",
        "\n",
        "\n",
        "    model = model.to(device)\n",
        "    \n",
        "    inputs = torch.Tensor(inputs).to(device)\n",
        "    forecasts = torch.Tensor(forecasts).to(device)\n",
        "    actuals = torch.Tensor(actuals).to(device)\n",
        "    mask = mask.to(device)\n",
        "\n",
        "    y_pred = model(inputs).unsqueeze(2)  # Array containing tensors of weighted average for all forecasts\n",
        "\n",
        "    normalization_weights = actuals[:,0:1]\n",
        "\n",
        "    normalized_actuals = actuals / normalization_weights\n",
        "\n",
        "    prediction = torch.matmul(forecasts, y_pred).squeeze(2) / normalization_weights\n",
        "\n",
        "    loss = loss_function(prediction.masked_select(mask), normalized_actuals.masked_select(mask))\n",
        "\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw_xAsDZ4wle"
      },
      "source": [
        "runpath = \"Models/211109_weightnet_robust_sweep_97/\"\n",
        "\n",
        "loss_function = loss_functions[\"sm\"]\n",
        "\n",
        "losses = test_loss(test_df, runpath, loss_function, use_meta=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHIrz2DY7RMB"
      },
      "source": [
        "losses.mean().item() * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ici5RH9--cdO"
      },
      "source": [
        "robust smape 11.787387728691101\n",
        "desert smape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9qWiol8h6A1"
      },
      "source": [
        "#Outdated "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6aWSJUPG6tH"
      },
      "source": [
        "net_untrained = Dense_net(42,9)\n",
        "plt.rcParams[\"figure.figsize\"] = (16,8)\n",
        "def plot_some_forecast_and_actuals(net, n_plots):\n",
        "    \n",
        "    for i in random.sample(range(5000), k=n_plots): \n",
        "      \n",
        "      inputs, forecasts, actuals, mask = feature_extractor(meta_train.iloc[[i]], \"m\", \"minmax\")\n",
        "      y_pred = net(inputs).unsqueeze(2)\n",
        "      y_pred_2 = net_untrained(inputs).unsqueeze(2)\n",
        "      \n",
        "      #print(\"trained\", y_pred)\n",
        "      #print(\"untrained\", y_pred_2)\n",
        "\n",
        "      \n",
        "      method_forecast_tup = []\n",
        "\n",
        "      predictions = torch.matmul(forecasts, y_pred).squeeze(2)\n",
        "      predictions_un = torch.matmul(forecasts, y_pred_2).squeeze(2)\n",
        "\n",
        "      plt.title(i)\n",
        "      plt.plot(predictions.detach().numpy()[0], label=\"prediction\")\n",
        "      plt.plot(predictions_un.detach().numpy()[0], label=\"Untrained prediction\")\n",
        "      plt.plot(actuals.detach().numpy()[0], label=\"actual\")\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "\n",
        "plot_some_forecast_and_actuals(net, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nACPpjG0znMG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}